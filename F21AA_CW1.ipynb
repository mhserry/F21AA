{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Loading Reviews to Dataframe...\n",
    "print('Loading reviews...',end='')\n",
    "df = pd.read_csv('train.csv')\n",
    "print('[ok]')\n",
    "print('Loaded {:,} reviews' .format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns #Deciding on Columns we might need, dropping the rest for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "We Found relatively Small number of NAN onject in the dataset  in both TEXT and Summary features\n",
    "wE will replace with '' and drop the UN-NEEDED columns for now\n",
    "\"\"\"\n",
    "df.Summary.fillna('', inplace=True)\n",
    "df.Text.fillna('', inplace=True)\n",
    "df.drop(['Id','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','ProductId'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data Exploration and Visualization: (10%)\n",
    "Provide an initial step to inspect, visualize and analyse the different attributes in your data set.\n",
    "Document your findings and make conclusions for your next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Concatinating TEXT and Summary features as per the DR. example. Which is OK as I didnt find obvious correlation\n",
    "df['text']=df['Summary']+' '+df['Text'] \n",
    "df.drop(['Summary','Text'],axis=1,inplace=True)\n",
    "df['length']=df['text'].str.len() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.hist()\n",
    "# We need to comment on the graph below, Basically the data is biased towards score 5 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('Score').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We can conclude from the table above, that the distributions is not equal, text with ratings 5 are far more than any other score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.hist(column='length',by='Score',bins=200,figsize=(8,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We need to write the conclustion for the graph\n",
    "#ALso feel free to add whatever graph you like so we can visualize the data as much as we can\n",
    "# DataFrame is called df , you can see its columns by running df.columns for more info run  df.info(), df.describe() ...etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Text Processing and Normalization: (20%)\n",
    "Thoroughly experiment with different text processing and normalization alternatives. Explain the\n",
    "trade-off and benefits of using each and justify their effectiveness for the current data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "NOTE FOR THE TEAM\n",
    "This question (Question 2) is all about text normalization (tokenization) , this includes\n",
    "cleaning the text and make it uniform, this is mainly done via removing punctuations, stopword\n",
    "After our call, I noticed some html tags in the text, we need to remove them as well.\n",
    "The catch is they MUST be removed before the pre-processing function , the reason is once we use the function, we loose punctuations, \n",
    "so <br> looks like br , so we cant really figure out that it was in fact and HTML tag.\n",
    "SO I will work on creating a fn to clean the html tags first, then pass it to the tokenization function \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Update, I found a libraries that can do that, you need to install \n",
    "pip install lxml\n",
    "pip install beautifulsoup4\n",
    "Added them to the tokenizer function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We will use 2 methods to tokeinze the corpse...stemming and Lemmatization , both from NLTK librarry\n",
    "\n",
    "#Once we finzalie the analysis, we will use CV and TFIDF to vectorize then build the pipeline with either one of them (cant have both in pipline AFAIK)\n",
    "# (possibly we will use TFIDF)\n",
    "\n",
    "#UPDATE, we will only remove the html tags and puncations ( we wont test that i believe as this will make the model better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Method 1 - Building our own tokenizer (to remove HTML and punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import string,lxml,bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "string.punctuation # we will remove this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#This function will remove html tags, punctiaton [Must run in order ]\n",
    "def tokenizer(text):\n",
    "    no_html = bs4.BeautifulSoup(text,'lxml').get_text()\n",
    "    no_punctuation = [char for char in no_html if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_original = df.copy() #Backup to work on raw input data if we will need it later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTNAT... THIS IS CREATING A SMALLER SUBSET OF DATA, REMOVE THIS LINE TO WORK ON ALL DATA\n",
    "df = df.head(1000)\n",
    "print ( 'Original DB size is',len(df_original),' Current db size',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Port Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_PS = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nltkstemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    review = [nltkstemmer.stem(word) for word in text.split()]\n",
    "    review = ' '.join(review) \n",
    "    return review\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_PS['text']= df_PS['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# decided to go with option v, not n for no obvoius reason except my surface laptop is burning hot :)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_LM = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nltklem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    review = [nltklem.lemmatize(word,'v') for word in text.lower().split()]\n",
    "    review = ' '.join(review)\n",
    "    #print(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_LM['text'] = df_LM['text'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the 3 datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "i=15 #set i to the record you wanna see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_original['text'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['text'].iloc[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_PS['text'].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_LM['text'].loc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Write our conclusion here...!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector space Model and feature representation: (20%)\n",
    "Experiment with different representation techniques. Document your findings and make\n",
    "conclusions. Show how choosing n-gram features can influence your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVictorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Method1 df | CountVectorizer (defualt 'word' analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m1 = CountVectorizer().fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m1 = bow_m1.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Method2 df | CountVectorizer(our custom analyzer aka Tokenizer)\n",
    "\n",
    "# Fitting \n",
    "bow_m2 = CountVectorizer(analyzer=tokenizer).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m2 = bow_m2.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Method3 df | CountVectorizer(char analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m3 = CountVectorizer(analyzer='char').fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m3 = bow_m3.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Method4 df | CountVectorizer(stop words )\n",
    "\n",
    "# Fitting \n",
    "bow_m4 = CountVectorizer(stop_words={'english'},analyzer= 'word',ngram_range=(1,2)).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m4 = bow_m4.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#findings and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 1 CV')\n",
    "print('Bag of words CV1',len(bow_m1.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 2 CV')\n",
    "print('Bag of words CV2',len(bow_m2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 3 CV')\n",
    "print('Bag of words CV3',len(bow_m3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 4 CV')\n",
    "print('Bag of words CV4',len(bow_m4.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "BOW_TFIDF1 = TfidfVectorizer(stop_words={'english'},ngram_range=(1,2))\n",
    "BOW_TFIDF1.fit(df['text'])\n",
    "#BOW_TFIDF1.fit_transform(df_small['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "BOW_TFIDF2 = TfidfVectorizer(analyzer=tokenizer,ngram_range=(1,2))\n",
    "BOW_TFIDF2.fit(df['text'])\n",
    "#BOW_TFIDF1.fit_transform(df_small['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "BOW_TFIDF3 = TfidfVectorizer(ngram_range=(1,2),min_df=2)\n",
    "BOW_TFIDF3.fit(df['text'])\n",
    "#BOW_TFIDF1.fit_transform(df_small['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 1 TFIDF')\n",
    "print('Bag of words TFIDF1',len(BOW_TFIDF1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 2 TFIDF')\n",
    "print('Bag of words TFIDF2',len(BOW_TFIDF2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Method 3 TFIDF')\n",
    "print('Bag of words TFIDF3',len(BOW_TFIDF3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training, selection and hyperparameter tuning and evaluation:(20%)\n",
    "You should at least experiment with 3 models and show how you can optimize model\n",
    "parameters using cross validation. For each model discuss your choices of text processing,\n",
    "representation and features from steps 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}