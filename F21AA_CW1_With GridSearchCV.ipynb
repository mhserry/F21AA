{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...[ok]\n",
      "Loaded 426,340 reviews\n"
     ]
    }
   ],
   "source": [
    "#Loading Reviews to Dataframe...\n",
    "print('Loading reviews...',end='')\n",
    "df = pd.read_csv('train.csv')\n",
    "print('[ok]')\n",
    "print('Loaded {:,} reviews' .format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #Deciding on Columns we might need, dropping the rest for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We Found relatively Small number of NAN onject in the dataset  in both TEXT and Summary features\n",
    "#wE will replace with '' and drop the UN-NEEDED columns for now\n",
    "#Concatinating TEXT and Summary features as per the DR. example. Which is OK as I didnt find obvoius correlation\n",
    "def dataframe_optimzer(dataframe):\n",
    "    dataframe.Summary.fillna('', inplace=True)\n",
    "    dataframe.Text.fillna('', inplace=True)\n",
    "    dataframe.drop(['Id','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','ProductId'],axis=1,inplace=True)\n",
    "    #Concatinating TEXT and Summary features as per the DR. example. Which is OK as I didnt find obvoius correlation\n",
    "    dataframe['text']=dataframe['Summary']+' '+dataframe['Text'] \n",
    "    dataframe.drop(['Summary','Text'],axis=1,inplace=True)\n",
    "    #dataframe['length']=dataframe['text'].str.len() \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data Exploration and Visualization: (10%)\n",
    "Provide an initial step to inspect, visualize and analyse the different attributes in your data set.\n",
    "Document your findings and make conclusions for your next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe_optimzer(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Score', 'text'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000015E242C5588>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "# We need to comment on the graph below, Basically the data is biased towards score 5 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39193</td>\n",
       "      <td>28530</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22353</td>\n",
       "      <td>16290</td>\n",
       "      <td>Personal preference I had hoped this tea would...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31993</td>\n",
       "      <td>23302</td>\n",
       "      <td>I'll pass... Not enough flavor, murky brown co...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60309</td>\n",
       "      <td>43879</td>\n",
       "      <td>Stash Chamomile Herbal Tea Stash Chamomile Her...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>272492</td>\n",
       "      <td>197187</td>\n",
       "      <td>Fantastic Food for Good Cat Health The pet foo...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text                                                                \n",
       "        count  unique                                                top freq\n",
       "Score                                                                        \n",
       "1       39193   28530  Filler food is empty, leaves your cat always n...  140\n",
       "2       22353   16290  Personal preference I had hoped this tea would...   23\n",
       "3       31993   23302  I'll pass... Not enough flavor, murky brown co...   22\n",
       "4       60309   43879  Stash Chamomile Herbal Tea Stash Chamomile Her...   30\n",
       "5      272492  197187  Fantastic Food for Good Cat Health The pet foo...   37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Score').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can conclude from the table above, that the distributions is not equal, text with ratings 5 are far more than any other score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to write the conclustion for the graph\n",
    "#ALso feel free to add whatever graph you like so we can visualize the data as much as we can\n",
    "# DataFrame is called df , you can see its columns by running df.columns for more info run  df.info(), df.describe() ...etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Text Processing and Normalization: (20%)\n",
    "Thoroughly experiment with different text processing and normalization alternatives. Explain the\n",
    "trade-off and benefits of using each and justify their effectiveness for the current data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "NOTE FOR THE TEAM\n",
    "This question (Question 2) is all about text normalization (tokenization) , this includes\n",
    "cleaning the text and make it uniform, this is mainly done via removing punctuations, stopword\n",
    "After our call, I noticed some html tags in the text, we need to remove them as well.\n",
    "The catch is they MUST be removed before the pre-processing function , the reason is once we use the function, we loose punctuations, \n",
    "so <br> looks like br , so we cant really figure out that it was in fact and HTML tag.\n",
    "SO I will work on creating a fn to clean the html tags first, then pass it to the tokenization function \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Update, I found a libraries that can do that, you need to install \n",
    "pip install lxml\n",
    "pip install beautifulsoup4\n",
    "Added them to the tokenizer function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 2 methods to tokeinze the corpse...stemming and Lemmatization , both from NLTK librarry\n",
    "\n",
    "#Once we finzalie the analysis, we will use CV and TFIDF to vectorize then build the pipeline with either one of them (cant have both in pipline AFAIK)\n",
    "# (possibly we will use TFIDF)\n",
    "\n",
    "#UPDATE, we will only remove the html tags and puncations ( we wont test that i believe as this will make the model better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 - Building our own tokenizer (to remove HTML and punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,lxml,bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation # we will remove this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will remove html tags, punctiaton [Must run in order ]\n",
    "def tokenizer(text):\n",
    "    no_html = bs4.BeautifulSoup(text,'lxml').get_text()\n",
    "    no_punctuation = [char for char in no_html if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy() #Backup to work on raw input data if we will need it later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DB size is 426340  Current db size 1000\n"
     ]
    }
   ],
   "source": [
    "# IMPORTNAT... THIS IS CREATING A SMALLER SUBSET OF DATA, REMOVE THIS LINE TO WORK ON ALL DATA\n",
    "df = df.head(1000)\n",
    "print ( 'Original DB size is',len(df_original),' Current db size',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'] = df['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Port Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PS = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltkstemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    review = [nltkstemmer.stem(word) for word in text.split()]\n",
    "    review = ' '.join(review) \n",
    "    return review\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PS['text']= df_PS['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided to go with option v, not n for no obvoius reason except my surface laptop is burning hot :)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LM = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltklem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    review = [nltklem.lemmatize(word,'v') for word in text.lower().split()]\n",
    "    review = ' '.join(review)\n",
    "    #print(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LM['text'] = df_LM['text'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the 3 datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=15 #set i to the record you wanna see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEST CHIPS and GLUTEN FREE! These chips are so good they are addictive!  Extremely fresh and crispy.  Even potato chips can contain gluten, so when I noticed Gluten Free marked on the bag I had to give them a try.  Now these are the only potato chips I will purchase--Thanks for making a GF product that rocks!!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['text'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEST CHIPS and GLUTEN FREE! These chips are so good they are addictive!  Extremely fresh and crispy.  Even potato chips can contain gluten, so when I noticed Gluten Free marked on the bag I had to give them a try.  Now these are the only potato chips I will purchase--Thanks for making a GF product that rocks!!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best chip and gluten free! these chip are so good they are addictive! extrem fresh and crispy. even potato chip can contain gluten, so when I notic gluten free mark on the bag I had to give them a try. now these are the onli potato chip I will purchase--thank for make a GF product that rocks!!'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PS['text'].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best chip and gluten free! these chip be so good they be addictive! extremely fresh and crispy. even potato chip can contain gluten, so when i notice gluten free mark on the bag i have to give them a try. now these be the only potato chip i will purchase--thanks for make a gf product that rocks!!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LM['text'].loc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our conclusion here...!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector space Model and feature representation: (20%)\n",
    "Experiment with different representation techniques. Document your findings and make\n",
    "conclusions. Show how choosing n-gram features can influence your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVictorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method1 df | CountVectorizer (defualt 'word' analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m1 = CountVectorizer().fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m1 = bow_m1.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method2 df | CountVectorizer(our custom analyzer aka Tokenizer)\n",
    "\n",
    "# Fitting \n",
    "bow_m2 = CountVectorizer(analyzer=tokenizer).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m2 = bow_m2.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method3 df | CountVectorizer(char analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m3 = CountVectorizer(analyzer='char').fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m3 = bow_m3.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method4 df | CountVectorizer(stop words )\n",
    "\n",
    "# Fitting \n",
    "bow_m4 = CountVectorizer(stop_words={'english'},analyzer= 'word',ngram_range=(1,2)).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m4 = bow_m4.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 CV\n",
      "Bag of words CV1 7175\n"
     ]
    }
   ],
   "source": [
    "print('Method 1 CV')\n",
    "print('Bag of words CV1',len(bow_m1.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 CV\n",
      "Bag of words CV2 66\n"
     ]
    }
   ],
   "source": [
    "print('Method 2 CV')\n",
    "print('Bag of words CV2',len(bow_m2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3 CV\n",
      "Bag of words CV3 67\n"
     ]
    }
   ],
   "source": [
    "print('Method 3 CV')\n",
    "print('Bag of words CV3',len(bow_m3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4 CV\n",
      "Bag of words CV4 53569\n"
     ]
    }
   ],
   "source": [
    "print('Method 4 CV')\n",
    "print('Bag of words CV4',len(bow_m4.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF1 = TfidfVectorizer(stop_words={'english'},ngram_range=(1,2))\n",
    "BOW_TFIDF1.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tamers\\AppData\\Local\\Continuum\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'ngram_range' will not be used since 'analyzer' is callable'\n",
      "  warnings.warn(\"The parameter 'ngram_range' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF2 = TfidfVectorizer(analyzer=tokenizer,ngram_range=(1,2))\n",
    "BOW_TFIDF2.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF3 = TfidfVectorizer(ngram_range=(1,2),min_df=2)\n",
    "BOW_TFIDF3.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 TFIDF\n",
      "Bag of words TFIDF1 53569\n"
     ]
    }
   ],
   "source": [
    "print('Method 1 TFIDF')\n",
    "print('Bag of words TFIDF1',len(BOW_TFIDF1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 TFIDF\n",
      "Bag of words TFIDF2 66\n"
     ]
    }
   ],
   "source": [
    "print('Method 2 TFIDF')\n",
    "print('Bag of words TFIDF2',len(BOW_TFIDF2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3 TFIDF\n",
      "Bag of words TFIDF3 12333\n"
     ]
    }
   ],
   "source": [
    "print('Method 3 TFIDF')\n",
    "print('Bag of words TFIDF3',len(BOW_TFIDF3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training, selection and hyperparameter tuning and evaluation:(20%)\n",
    "You should at least experiment with 3 models and show how you can optimize model\n",
    "parameters using cross validation. For each model discuss your choices of text processing,\n",
    "representation and features from steps 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test Data\n",
    "df_test_data = dataframe_optimzer(pd.read_csv(\"test.csv\"))\n",
    "df_test_labels = pd.read_csv(\"labels.csv\",usecols=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to cross validate unseen data\n",
    "def classification_report_final (model): \n",
    "    y_pred_final = model.predict(df_test_data['text'])\n",
    "    score_final =accuracy_score(df_test_labels,y_pred_final)\n",
    "    print('Model score on unseen data',score_final)\n",
    "    print (classification_report(df_test_labels,y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Pipeline and using Gridsearch to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Supressing Warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df['Score'].copy()\n",
    "df_data = df['text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data = dataframe_optimzer(pd.read_csv(\"test.csv\"))\n",
    "df_test_labels = pd.read_csv(\"labels.csv\",usecols=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(df_data, df_label, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [LogisticRegression,MultinomialNB,SGDClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(estimator): #not my code\n",
    "    \n",
    "    pipeline_steps = [\n",
    "        \n",
    "        ('cv',CountVectorizer()),\n",
    "        ('tfidf',TfidfTransformer()),\n",
    "        ('classifier',estimator)\n",
    "    ]\n",
    "    \n",
    "    return Pipeline(pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating disctoinaries for every estmimator to load the optmization paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  parameters for Grid Search (CV and TfIdf) - BASE \n",
    "param_grid= {}\n",
    "\n",
    "#Parameters for CountVectorizer\n",
    "param_grid.update({'cv__ngram_range':[(1,1),(1,2),(1,3)]})\n",
    "param_grid.update({'cv__stop_words':[None,'english']})\n",
    "#param_grid.update({'cv__max_df':[1,2]})\n",
    "param_grid.update({'cv__analyzer':[tokenizer,lemmatizer,'word']})\n",
    "\n",
    "\n",
    "#Parameters of TFIDF\n",
    "param_grid.update({'tfidf__use_idf':[True,False]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  parameters for Grid Search (CV and TfIdf) - BASE \n",
    "param_grid= {}\n",
    "\n",
    "#Parameters for CountVectorizer\n",
    "param_grid.update({})\n",
    "param_grid.update({})\n",
    "#param_grid.update({})\n",
    "param_grid.update({})\n",
    "\n",
    "\n",
    "#Parameters of TFIDF\n",
    "param_grid.update({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for LR\n",
    "param_grid_LR = {}\n",
    "param_grid_LR = {'classifier__C':[0.0001,0.001]}\n",
    "param_grid_LR.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for LR\n",
    "param_grid_LR = {}\n",
    "param_grid_LR = {}\n",
    "param_grid_LR.update(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for MN\n",
    "param_grid_MN = {}\n",
    "param_grid_MN = {'classifier__alpha':[0.0001]}\n",
    "param_grid_MN.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for MN\n",
    "param_grid_MN = {}\n",
    "param_grid_MN = {}\n",
    "param_grid_MN.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for SGD here\n",
    "param_grid_SG={}\n",
    "param_grid_SG.update(param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    LogisticRegression : param_grid_LR,\n",
    "    MultinomialNB : param_grid_MN,\n",
    "    SGDClassifier : param_grid_SG\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression scored 0.66\n",
      "Best parameter (CV score=0.653):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.67      1.00      0.80       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.13      0.20      0.16       250\n",
      "weighted avg       0.44      0.66      0.53       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6400636109039222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.01      0.02     13075\n",
      "           2       0.00      0.00      0.00      7416\n",
      "           3       1.00      0.00      0.00     10647\n",
      "           4       0.33      0.01      0.03     20346\n",
      "           5       0.64      1.00      0.78     90630\n",
      "\n",
      "    accuracy                           0.64    142114\n",
      "   macro avg       0.52      0.20      0.17    142114\n",
      "weighted avg       0.59      0.64      0.50    142114\n",
      "\n",
      "MultinomialNB scored 0.66\n",
      "Best parameter (CV score=0.652):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.66      1.00      0.80       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.13      0.20      0.16       250\n",
      "weighted avg       0.44      0.66      0.52       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6377274582377528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     13075\n",
      "           2       0.00      0.00      0.00      7416\n",
      "           3       0.00      0.00      0.00     10647\n",
      "           4       0.00      0.00      0.00     20346\n",
      "           5       0.64      1.00      0.78     90630\n",
      "\n",
      "    accuracy                           0.64    142114\n",
      "   macro avg       0.13      0.20      0.16    142114\n",
      "weighted avg       0.41      0.64      0.50    142114\n",
      "\n",
      "SGDClassifier scored 0.66\n",
      "Best parameter (CV score=0.675):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.21      0.29        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.38      0.14      0.21        21\n",
      "           4       0.22      0.18      0.20        33\n",
      "           5       0.76      0.92      0.83       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.36      0.29      0.30       250\n",
      "weighted avg       0.61      0.66      0.62       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6526309863912071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.29      0.37     13075\n",
      "           2       0.25      0.06      0.10      7416\n",
      "           3       0.32      0.11      0.16     10647\n",
      "           4       0.26      0.19      0.22     20346\n",
      "           5       0.73      0.92      0.81     90630\n",
      "\n",
      "    accuracy                           0.65    142114\n",
      "   macro avg       0.42      0.31      0.33    142114\n",
      "weighted avg       0.59      0.65      0.60    142114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator,search_param in estimators.items():\n",
    "    scores=[]\n",
    "    model = create_pipeline(estimator())\n",
    "    search=GridSearchCV(model,search_param,n_jobs=-1)\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    scores.append(score)\n",
    "    print(estimator.__name__,'scored',score)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    print (classification_report(y_test,y_pred))\n",
    "    print('\\n')\n",
    "    print('Cross validation with unseen test data  test data , not used in training')\n",
    "    classification_report_final(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (5, 7117)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn as mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "food          tea           coffee        chips         chocolate     \n",
      "he            best          price         bag           water         \n",
      "cat           your          dog           popcorn       coffee        \n",
      "coffee        find          buy           free          coconut       \n",
      "up            teas          use           favorite      hot           \n",
      "don           dog           an            too           salt          \n",
      "after         cookies       up            tried         too           \n",
      "cats          their         only          fat           sauce         \n",
      "there         only          really        best          milk          \n",
      "your          box           were          little        tried         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
