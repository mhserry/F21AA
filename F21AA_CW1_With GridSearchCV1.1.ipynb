{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tamers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports and Functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string,lxml,bs4,nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from warnings import simplefilter\n",
    "\n",
    "def dataframe_optimzer(dataframe):\n",
    "    dataframe.Summary.fillna('', inplace=True)\n",
    "    dataframe.Text.fillna('', inplace=True)\n",
    "    dataframe.drop(['Id','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','ProductId'],axis=1,inplace=True)\n",
    "    #Concatinating TEXT and Summary features as per the DR. example. Which is OK as I didnt find obvoius correlation\n",
    "    dataframe['text']=dataframe['Summary']+' '+dataframe['Text'] \n",
    "    dataframe.drop(['Summary','Text'],axis=1,inplace=True)\n",
    "    #dataframe['length']=dataframe['text'].str.len() \n",
    "    return dataframe\n",
    "\n",
    "def tokenizer(text):\n",
    "    no_html = bs4.BeautifulSoup(text,'lxml').get_text()\n",
    "    no_punctuation = [char for char in no_html if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return no_punctuation\n",
    "\n",
    "def stemmer(text):\n",
    "    review = [nltkstemmer.stem(word) for word in text.split()]\n",
    "    review = ' '.join(review) \n",
    "    return review\n",
    "\n",
    "def lemmatizer(text):\n",
    "    review = [nltklem.lemmatize(word,'v') for word in text.lower().split()]\n",
    "    review = ' '.join(review)\n",
    "    #print(review)\n",
    "    return review\n",
    "\n",
    "def classification_report_final (model): \n",
    "    y_pred_final = model.predict(df_test_data['text'])\n",
    "    score_final =accuracy_score(df_test_labels,y_pred_final)\n",
    "    print('Model score on unseen data',score_final)\n",
    "    print (classification_report(df_test_labels,y_pred_final))\n",
    "\n",
    "def dataloading():\n",
    "    print('Loading reviews...',end='')\n",
    "    df = pd.read_csv('train.csv')\n",
    "    print('[ok]')\n",
    "    print('Loaded {:,} reviews' .format(len(df)))\n",
    "    \n",
    "    df=df.head(1000)  # <--- Dataset limiter ia here, Can change\n",
    "    \n",
    "    print('applying dataframe optimizer...',end='')\n",
    "    df = dataframe_optimzer(df)\n",
    "    print('[OK]')\n",
    "\n",
    "    print('applying dataframe tokenizer...',end='')\n",
    "    df['text'].apply(tokenizer)\n",
    "    print('[OK]')\n",
    "    return df\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltklem = WordNetLemmatizer()\n",
    "nltkstemmer = PorterStemmer()\n",
    "simplefilter(action='ignore', category=Warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...[ok]\n",
      "Loaded 426,340 reviews\n",
      "applying dataframe optimizer...[OK]\n",
      "applying dataframe tokenizer...[OK]\n"
     ]
    }
   ],
   "source": [
    "df = dataloading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Score', 'text'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #Deciding on Columns we might need, dropping the rest for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data Exploration and Visualization: (10%)\n",
    "Provide an initial step to inspect, visualize and analyse the different attributes in your data set.\n",
    "Document your findings and make conclusions for your next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Score', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001DEAD873148>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "# We need to comment on the graph below, Basically the data is biased towards score 5 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>Not a fan I bought 2 boxes of San Francisco Ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>Did something change? The following is a revie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>Mints are much better I really enjoyed the cup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>Cool Movie A cool movie with some very funny a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>654</td>\n",
       "      <td>654</td>\n",
       "      <td>Great stuff I bought this for my wife, and she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                                               \n",
       "      count unique                                                top freq\n",
       "Score                                                                     \n",
       "1        92     92  Not a fan I bought 2 boxes of San Francisco Ba...    1\n",
       "2        43     43  Did something change? The following is a revie...    1\n",
       "3        68     68  Mints are much better I really enjoyed the cup...    1\n",
       "4       143    143  Cool Movie A cool movie with some very funny a...    1\n",
       "5       654    654  Great stuff I bought this for my wife, and she...    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Score').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Text Processing and Normalization: (20%)\n",
    "Thoroughly experiment with different text processing and normalization alternatives. Explain the\n",
    "trade-off and benefits of using each and justify their effectiveness for the current data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "NOTE FOR THE TEAM\n",
    "This question (Question 2) is all about text normalization (tokenization) , this includes\n",
    "cleaning the text and make it uniform, this is mainly done via removing punctuations, stopword\n",
    "After our call, I noticed some html tags in the text, we need to remove them as well.\n",
    "The catch is they MUST be removed before the pre-processing function , the reason is once we use the function, we loose punctuations, \n",
    "so <br> looks like br , so we cant really figure out that it was in fact and HTML tag.\n",
    "SO I will work on creating a fn to clean the html tags first, then pass it to the tokenization function \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Update, I found a libraries that can do that, you need to install \n",
    "pip install lxml\n",
    "pip install beautifulsoup4\n",
    "Added them to the tokenizer function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 - Building our own tokenizer (to remove HTML and punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy() #Backup to work on raw input data if we will need it later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DB size is 1000  Current db size 1000\n"
     ]
    }
   ],
   "source": [
    "# IMPORTNAT... THIS IS CREATING A SMALLER SUBSET OF DATA, REMOVE THIS LINE TO WORK ON ALL DATA\n",
    "df = df.head(1000)\n",
    "print ( 'Original DB size is',len(df_original),' Current db size',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Port Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PS = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltkstemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    review = [nltkstemmer.stem(word) for word in text.split()]\n",
    "    review = ' '.join(review) \n",
    "    return review\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PS['text']= df_PS['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided to go with option v, not n for no obvoius reason except my surface laptop is burning hot :)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LM = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltklem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LM['text'] = df_LM['text'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the 3 datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=15 #set i to the record you wanna see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEST CHIPS and GLUTEN FREE! These chips are so good they are addictive!  Extremely fresh and crispy.  Even potato chips can contain gluten, so when I noticed Gluten Free marked on the bag I had to give them a try.  Now these are the only potato chips I will purchase--Thanks for making a GF product that rocks!!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['text'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEST CHIPS and GLUTEN FREE These chips are so good they are addictive  Extremely fresh and crispy  Even potato chips can contain gluten so when I noticed Gluten Free marked on the bag I had to give them a try  Now these are the only potato chips I will purchaseThanks for making a GF product that rocks'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best chip and gluten free these chip are so good they are addict extrem fresh and crispi even potato chip can contain gluten so when I notic gluten free mark on the bag I had to give them a tri now these are the onli potato chip I will purchasethank for make a GF product that rock'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PS['text'].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best chip and gluten free these chip be so good they be addictive extremely fresh and crispy even potato chip can contain gluten so when i notice gluten free mark on the bag i have to give them a try now these be the only potato chip i will purchasethanks for make a gf product that rock'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LM['text'].loc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector space Model and feature representation: (20%)\n",
    "Experiment with different representation techniques. Document your findings and make\n",
    "conclusions. Show how choosing n-gram features can influence your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVictorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...[ok]\n",
      "Loaded 426,340 reviews\n",
      "applying dataframe optimizer...[OK]\n",
      "applying dataframe tokenizer...[OK]\n"
     ]
    }
   ],
   "source": [
    "df = dataloading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method1 df | CountVectorizer (defualt 'word' analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m1 = CountVectorizer().fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m1 = bow_m1.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method2 df | CountVectorizer(our custom analyzer aka Tokenizer)\n",
    "\n",
    "# Fitting \n",
    "bow_m2 = CountVectorizer(analyzer=tokenizer).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m2 = bow_m2.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method3 df | CountVectorizer(char analyzer)\n",
    "\n",
    "# Fitting \n",
    "bow_m3 = CountVectorizer(analyzer='char').fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m3 = bow_m3.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method4 df | CountVectorizer(stop words )\n",
    "\n",
    "# Fitting \n",
    "bow_m4 = CountVectorizer(stop_words={'english'},analyzer= 'word',ngram_range=(1,2)).fit(df['text'])\n",
    "#Transform \n",
    "df_small_bow_m4 = bow_m4.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 CV\n",
      "Bag of words CV1 7175\n"
     ]
    }
   ],
   "source": [
    "print('Method 1 CV')\n",
    "print('Bag of words CV1',len(bow_m1.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 CV\n",
      "Bag of words CV2 66\n"
     ]
    }
   ],
   "source": [
    "print('Method 2 CV')\n",
    "print('Bag of words CV2',len(bow_m2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3 CV\n",
      "Bag of words CV3 67\n"
     ]
    }
   ],
   "source": [
    "print('Method 3 CV')\n",
    "print('Bag of words CV3',len(bow_m3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4 CV\n",
      "Bag of words CV4 53569\n"
     ]
    }
   ],
   "source": [
    "print('Method 4 CV')\n",
    "print('Bag of words CV4',len(bow_m4.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF1 = TfidfVectorizer(stop_words={'english'},ngram_range=(1,2))\n",
    "BOW_TFIDF1.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF2 = TfidfVectorizer(analyzer=tokenizer,ngram_range=(1,2))\n",
    "BOW_TFIDF2.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x53569 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_TFIDF3 = TfidfVectorizer(ngram_range=(1,2),min_df=2)\n",
    "BOW_TFIDF3.fit(df['text'])\n",
    "BOW_TFIDF1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 TFIDF\n",
      "Bag of words TFIDF1 53569\n"
     ]
    }
   ],
   "source": [
    "print('Method 1 TFIDF')\n",
    "print('Bag of words TFIDF1',len(BOW_TFIDF1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 TFIDF\n",
      "Bag of words TFIDF2 66\n"
     ]
    }
   ],
   "source": [
    "print('Method 2 TFIDF')\n",
    "print('Bag of words TFIDF2',len(BOW_TFIDF2.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3 TFIDF\n",
      "Bag of words TFIDF3 12333\n"
     ]
    }
   ],
   "source": [
    "print('Method 3 TFIDF')\n",
    "print('Bag of words TFIDF3',len(BOW_TFIDF3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training, selection and hyperparameter tuning and evaluation:(20%)\n",
    "You should at least experiment with 3 models and show how you can optimize model\n",
    "parameters using cross validation. For each model discuss your choices of text processing,\n",
    "representation and features from steps 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...[ok]\n",
      "Loaded 426,340 reviews\n",
      "applying dataframe optimizer...[OK]\n",
      "applying dataframe tokenizer...[OK]\n"
     ]
    }
   ],
   "source": [
    "df=dataloading()\n",
    "#Loading test Data\n",
    "df_test_data = dataframe_optimzer(pd.read_csv(\"test.csv\"))\n",
    "df_test_labels = pd.read_csv(\"labels.csv\",usecols=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df['Score'].copy()\n",
    "df_data = df['text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(df_data, df_label, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [LogisticRegression,MultinomialNB,SGDClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(estimator): #not my code\n",
    "    \n",
    "    pipeline_steps = [\n",
    "        \n",
    "        ('cv',CountVectorizer()),\n",
    "        ('tfidf',TfidfTransformer()),\n",
    "        ('classifier',estimator)\n",
    "    ]\n",
    "    \n",
    "    return Pipeline(pipeline_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for Grid Search (CV and TfIdf) - BASE \n",
    "param_grid= {}\n",
    "\n",
    "#Parameters for CountVectorizer\n",
    "param_grid.update({'cv__ngram_range':[(1,1),(1,2),(1,3)]})\n",
    "param_grid.update({'cv__stop_words':[None,'english']})\n",
    "#param_grid.update({'cv__max_df':[1,2]})\n",
    "param_grid.update({'cv__analyzer':[tokenizer,lemmatizer,'word']})\n",
    "\n",
    "\n",
    "#Parameters of TFIDF\n",
    "param_grid.update({'tfidf__use_idf':[True,False]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  parameters for Grid Search (CV and TfIdf) - BASE \n",
    "param_grid= {}\n",
    "\n",
    "#Parameters for CountVectorizer\n",
    "param_grid.update({})\n",
    "param_grid.update({})\n",
    "#param_grid.update({})\n",
    "param_grid.update({})\n",
    "\n",
    "\n",
    "#Parameters of TFIDF\n",
    "param_grid.update({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for LR\n",
    "param_grid_LR = {}\n",
    "param_grid_LR = {'classifier__C':[0.0001,0.001]}\n",
    "param_grid_LR.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for LR\n",
    "param_grid_LR = {}\n",
    "param_grid_LR = {}\n",
    "param_grid_LR.update(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for MN\n",
    "param_grid_MN = {}\n",
    "param_grid_MN = {'classifier__alpha':[0.0001]}\n",
    "param_grid_MN.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for MN\n",
    "param_grid_MN = {}\n",
    "param_grid_MN = {}\n",
    "param_grid_MN.update(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for SGD here\n",
    "param_grid_SG={}\n",
    "param_grid_SG.update(param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    LogisticRegression : param_grid_LR,\n",
    "    MultinomialNB : param_grid_MN,\n",
    "    SGDClassifier : param_grid_SG\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression scored 0.66\n",
      "Best parameter (CV score=0.653):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.67      1.00      0.80       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.13      0.20      0.16       250\n",
      "weighted avg       0.44      0.66      0.53       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6400636109039222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.01      0.02     13075\n",
      "           2       0.00      0.00      0.00      7416\n",
      "           3       1.00      0.00      0.00     10647\n",
      "           4       0.33      0.01      0.03     20346\n",
      "           5       0.64      1.00      0.78     90630\n",
      "\n",
      "    accuracy                           0.64    142114\n",
      "   macro avg       0.52      0.20      0.17    142114\n",
      "weighted avg       0.59      0.64      0.50    142114\n",
      "\n",
      "MultinomialNB scored 0.66\n",
      "Best parameter (CV score=0.652):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.66      1.00      0.80       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.13      0.20      0.16       250\n",
      "weighted avg       0.44      0.66      0.52       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6377274582377528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     13075\n",
      "           2       0.00      0.00      0.00      7416\n",
      "           3       0.00      0.00      0.00     10647\n",
      "           4       0.00      0.00      0.00     20346\n",
      "           5       0.64      1.00      0.78     90630\n",
      "\n",
      "    accuracy                           0.64    142114\n",
      "   macro avg       0.13      0.20      0.16    142114\n",
      "weighted avg       0.41      0.64      0.50    142114\n",
      "\n",
      "SGDClassifier scored 0.664\n",
      "Best parameter (CV score=0.675):\n",
      "{}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.21      0.29        24\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.38      0.14      0.21        21\n",
      "           4       0.30      0.27      0.29        33\n",
      "           5       0.78      0.90      0.83       165\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.38      0.31      0.32       250\n",
      "weighted avg       0.63      0.66      0.63       250\n",
      "\n",
      "\n",
      "\n",
      "Cross validation with unseen test data  test data , not used in training\n",
      "Model score on unseen data 0.6526591328088718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.29      0.38     13075\n",
      "           2       0.26      0.07      0.11      7416\n",
      "           3       0.31      0.10      0.15     10647\n",
      "           4       0.26      0.19      0.22     20346\n",
      "           5       0.73      0.92      0.81     90630\n",
      "\n",
      "    accuracy                           0.65    142114\n",
      "   macro avg       0.42      0.32      0.34    142114\n",
      "weighted avg       0.59      0.65      0.60    142114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator,search_param in estimators.items():\n",
    "    scores=[]\n",
    "    model = create_pipeline(estimator())\n",
    "    search=GridSearchCV(model,search_param,n_jobs=-1)\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    scores.append(score)\n",
    "    print(estimator.__name__,'scored',score)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    print (classification_report(y_test,y_pred))\n",
    "    print('\\n')\n",
    "    print('Cross validation with unseen test data  test data , not used in training')\n",
    "    classification_report_final(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (5, 7117)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn as mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "food          tea           coffee        chips         chocolate     \n",
      "he            best          price         bag           water         \n",
      "cat           your          dog           popcorn       coffee        \n",
      "coffee        find          buy           free          coconut       \n",
      "up            teas          use           favorite      hot           \n",
      "don           dog           an            too           salt          \n",
      "after         cookies       up            tried         too           \n",
      "cats          their         only          fat           sauce         \n",
      "there         only          really        best          milk          \n",
      "your          box           were          little        tried         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
